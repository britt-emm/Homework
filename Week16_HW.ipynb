{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71f85804",
   "metadata": {},
   "source": [
    "### 1.Perform combined over and undersampling on the diabetes dataset (use SMOTEENN). Explain how combined sampling works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6df8f9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix\n",
    "from imblearn.combine import SMOTEENN\n",
    "import pydotplus\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "diabetes_df = pd.read_csv(\"diabetes.csv\")\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78aabcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 350, 1: 187})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = diabetes_df.drop('Outcome', axis=1)\n",
    "y = diabetes_df['Outcome']\n",
    "\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42, stratify=y)\n",
    "\n",
    "#Standardize\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)\n",
    "print('Original dataset shape %s' % Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5462144a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1: 211, 0: 187})\n"
     ]
    }
   ],
   "source": [
    "# instantiate a SMOTEENN object\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_resampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d521880d",
   "metadata": {},
   "source": [
    "Oversampling adds more samples to the minority class, and undersampling removes samples from the majority class to help balance out a dataset where there is a large difference in the sizes of the classes that might skew a supervised learning algorithm to more often pick the majority class. Combined sampling allows you to do both oversampling and undersampling to balance out the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a92ad22",
   "metadata": {},
   "source": [
    "### 2.\tComment on the performance of combined sampling vs the other approaches we have used for the diabetes dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3881d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline output\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77       150\n",
      "           1       0.58      0.58      0.58        81\n",
      "\n",
      "    accuracy                           0.71       231\n",
      "   macro avg       0.68      0.68      0.68       231\n",
      "weighted avg       0.71      0.71      0.71       231\n",
      "\n",
      "SMOTEEN output\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.82      0.74      0.70      0.78      0.72      0.52       150\n",
      "          1       0.59      0.70      0.74      0.64      0.72      0.52        81\n",
      "\n",
      "avg / total       0.74      0.73      0.72      0.73      0.72      0.52       231\n",
      "\n",
      "Random Oversampler output\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.83      0.74      0.73      0.78      0.73      0.54       150\n",
      "          1       0.60      0.73      0.74      0.66      0.73      0.54        81\n",
      "\n",
      "avg / total       0.75      0.74      0.73      0.74      0.73      0.54       231\n",
      "\n",
      "Optimized Random Oversampler output\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.88      0.75      0.81      0.81      0.78      0.61       150\n",
      "          1       0.64      0.81      0.75      0.72      0.78      0.62        81\n",
      "\n",
      "avg / total       0.80      0.77      0.79      0.78      0.78      0.61       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# decision tree classifier\n",
    "model = tree.DecisionTreeClassifier(max_depth = 10,random_state=42)\n",
    "\n",
    "model = model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Baseline output')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\"\"\"SMOTEEN sample\"\"\"\n",
    "# decision tree classifier\n",
    "model = tree.DecisionTreeClassifier(max_depth = 10,random_state=42)\n",
    "\n",
    "combined = model.fit(X_resampled, y_resampled)\n",
    "#model = model.fit(X_test, y_test)\n",
    "y_pred = combined.predict(X_test)\n",
    "\n",
    "print('SMOTEEN output')\n",
    "#print(classification_report(y_test, y_pred))\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))\n",
    "\n",
    "\"\"\" Performance of random oversampled output, everything else the same\"\"\"\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_res, y_res= ros.fit_resample(X_train, y_train)\n",
    "\n",
    "model = model.fit(X_res, y_res)\n",
    "#model = model.fit(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Random Oversampler output')\n",
    "#print(classification_report(y_test, y_pred))\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))\n",
    "\n",
    "\"\"\"Performance of an oversampled output with change in depth\"\"\"\n",
    "X = diabetes_df[['Glucose','BMI','Age']]\n",
    "y = diabetes_df['Outcome']\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42, stratify=y)\n",
    "\n",
    "#Standardize\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)\n",
    "\n",
    "# decision tree classifier\n",
    "model = tree.DecisionTreeClassifier(max_depth = 5, random_state=42)\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_res, y_res= ros.fit_resample(X_train, y_train)\n",
    "\n",
    "model = model.fit(X_res, y_res)\n",
    "#model = model.fit(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Optimized Random Oversampler output')\n",
    "#print(classification_report(y_test, y_pred))\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed158b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTEEN output optimized\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.83      0.73      0.73      0.78      0.73      0.53       150\n",
      "          1       0.59      0.73      0.73      0.65      0.73      0.53        81\n",
      "\n",
      "avg / total       0.75      0.73      0.73      0.73      0.73      0.53       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = diabetes_df[['Glucose','BMI','Age']]\n",
    "y = diabetes_df['Outcome']\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42, stratify=y)\n",
    "\n",
    "#Standardize\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)\n",
    "\n",
    "\n",
    "\"\"\"Performance of combined sample with optimization\"\"\"\n",
    "# instantiate a SMOTEENN object\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "\n",
    "# decision tree classifier\n",
    "model = tree.DecisionTreeClassifier(max_depth = 6,random_state=42)\n",
    "\n",
    "combined = model.fit(X_resampled, y_resampled)\n",
    "#model = model.fit(X_test, y_test)\n",
    "y_pred = combined.predict(X_test)\n",
    "\n",
    "print('SMOTEEN output optimized')\n",
    "#print(classification_report(y_test, y_pred))\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c53fe25",
   "metadata": {},
   "source": [
    "The SMOTEEN output didn't do as well as the optimized random oversampler output for precision and recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39080671",
   "metadata": {},
   "source": [
    "### 3.\tWhat is outlier detection? Why is it useful? What methods can you use for outlier detection?\n",
    "\n",
    "Outlier detection identifies samples in a dataset that are very far from other samples and then ignores those samples. It is useful because outliers can skew your data.\n",
    "You can use sklearn's covariance EllipticEnvelope method which assumes a Gaussian distribution of the data and fit the data to an ellipse, anything outside the ellipse is considered an outlier.\n",
    "You can also use ensemble IsolationForest which creates a tree with a minimum number of splits and looks for terminating nodes that stop splitting too soon.\n",
    "You can also use the neighbors LocalOutlierFactor which uses k-nearest neighbors to look at the density of the number of neighbors around a sample, if the density of the sample is much smaller than the average density of other samples it's considered an outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abe1c11",
   "metadata": {},
   "source": [
    "### 4.\tPerform a linear SVM to predict credit approval (last column) using this dataset: https://archive.ics.uci.edu/ml/datasets/Statlog+%28Australian+Credit+Approval%29 . Make sure you look at the accompanying document that describes the data in the dat file. You will need to either convert this data to another file type or import the dat file to python. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43ecab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"australian.dat\") as infile, open(\"outfile.csv\", \"w\") as outfile:\n",
    "    csv_writer = csv.writer(outfile, delimiter=',')\n",
    "    \n",
    "    csv_writer.writerow(['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'A11', 'A12','A13', 'A14', 'A15'])\n",
    "    for line in infile:\n",
    "        row = [field.strip() for field in line.split(' ')]\n",
    "        csv_writer.writerow(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b921cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22.08</td>\n",
       "      <td>11.46</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>22.67</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>29.58</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>21.67</td>\n",
       "      <td>11.50</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.17</td>\n",
       "      <td>8.17</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.960</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1     A2     A3  A4  A5  A6     A7  A8  A9  A10  A11  A12  A13   A14  A15\n",
       "0   1  22.08  11.46   2   4   4  1.585   0   0    0    1    2  100  1213    0\n",
       "1   0  22.67   7.00   2   8   4  0.165   0   0    0    0    2  160     1    0\n",
       "2   0  29.58   1.75   1   4   4  1.250   0   0    0    1    2  280     1    0\n",
       "3   0  21.67  11.50   1   5   3  0.000   1   1   11    1    2    0     1    1\n",
       "4   1  20.17   8.17   2   6   4  1.960   1   1   14    0    2   60   159    1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "australia_df = pd.read_csv('outfile.csv')\n",
    "australia_df.head()\n",
    "# desired outcome is column A15 where + =1 and - = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b43356a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A1      690 non-null    int64  \n",
      " 1   A2      690 non-null    float64\n",
      " 2   A3      690 non-null    float64\n",
      " 3   A4      690 non-null    int64  \n",
      " 4   A5      690 non-null    int64  \n",
      " 5   A6      690 non-null    int64  \n",
      " 6   A7      690 non-null    float64\n",
      " 7   A8      690 non-null    int64  \n",
      " 8   A9      690 non-null    int64  \n",
      " 9   A10     690 non-null    int64  \n",
      " 10  A11     690 non-null    int64  \n",
      " 11  A12     690 non-null    int64  \n",
      " 12  A13     690 non-null    int64  \n",
      " 13  A14     690 non-null    int64  \n",
      " 14  A15     690 non-null    int64  \n",
      "dtypes: float64(3), int64(12)\n",
      "memory usage: 81.0 KB\n"
     ]
    }
   ],
   "source": [
    "australia_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a336629e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(690, 14)\n",
      "(690,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.75      0.83       115\n",
      "           1       0.75      0.93      0.83        92\n",
      "\n",
      "    accuracy                           0.83       207\n",
      "   macro avg       0.84      0.84      0.83       207\n",
      "weighted avg       0.85      0.83      0.83       207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear')\n",
    "\n",
    "X = australia_df.drop('A15', axis=1)\n",
    "y = np.array(australia_df['A15']).reshape(-1)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42, stratify=y)\n",
    "\n",
    "#Standardize\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#classifier.score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f02f9a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(690, 14)\n",
      "(690,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.77      0.85       115\n",
      "           1       0.76      0.95      0.84        92\n",
      "\n",
      "    accuracy                           0.85       207\n",
      "   macro avg       0.85      0.86      0.85       207\n",
      "weighted avg       0.86      0.85      0.85       207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "l_SVC = LinearSVC()\n",
    "\n",
    "X = australia_df.drop('A15', axis=1)\n",
    "y = np.array(australia_df['A15']).reshape(-1)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42, stratify=y)\n",
    "\n",
    "#Standardize\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)\n",
    "\n",
    "l_SVC.fit(X_train, y_train)\n",
    "y_pred = l_SVC.predict(X_test)\n",
    "\n",
    "#l_SVC.score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d75fbda",
   "metadata": {},
   "source": [
    "### 6.\tWhat kinds of jobs in data are you most interested in? Do some research on what is out there. Write about your thoughts in under 400 words. \n",
    "\n",
    "Ultimately I’m interested in a data scientist position but based on some of the job listings I’ve seen, it seems like I’m more likely to get my foot in the door as a data analyst and be able to work my way up to data scientist once I have more experience. I think I need to build up my statistics skills so that I’m better able to choose the right tools and be able to explain why it’s the right tool to use when it comes to machine learning. Perhaps if a company was willing to do some investing in me I could get a junior data scientist position. I am definitely interested in machine learning, creating visualizations and communicating what we've learned. \n",
    "I found a couple data scientist and data analyst positions with a few healthcare companies that could be a good fit building from my healthcare background, there was even one that didn't have experience as a requirement just as a preference. \n",
    "I think I would be a good fit for a consulting job based on my work experience as a contract therapist and ability to integrate into new teams well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
